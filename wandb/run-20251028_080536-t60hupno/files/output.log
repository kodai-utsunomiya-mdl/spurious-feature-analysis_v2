wandb is enabled and initialized.
Results will be saved to: results/wb_vit_scc_gf_example_2025-10-28_08-05-37
Using device: cuda

--- 1. Preparing Dataset ---

Displaying and saving 10 sample images from the WaterBirds train set...
Sample images saved to results/wb_vit_scc_gf_example_2025-10-28_08-05-37/dataset_samples.png

--- SCC-GF (Debias Method) Enabled ---
  Using SCC-GF mini-batch size: 64
  Calculated statistics and weights:
  E[Y] (y_bar) = -0.5358
  E[A] (a_bar) = -0.4824
  w_g(-1.0, -1.0) = 0.569146
  w_g(-1.0, 1.0) = 0.198737
  w_g(1.0, -1.0) = 0.172042
  w_g(1.0, 1.0) = 0.060074

--- Train Set Group Distribution (WaterBirds) ---
Waterbird on Water (y=+1, a=+1)    :  1057 samples
Waterbird on Land (y=+1, a=-1)     :    56 samples
Landbird on Water (y=-1, a=+1)     :   184 samples
Landbird on Land (y=-1, a=-1)      :  3498 samples
Total                              :  4795 samples


--- Test Set Group Distribution (WaterBirds) ---
Waterbird on Water (y=+1, a=+1)    :   642 samples
Waterbird on Land (y=+1, a=-1)     :   642 samples
Landbird on Water (y=-1, a=+1)     :  2255 samples
Landbird on Land (y=-1, a=-1)      :  2255 samples
Total                              :  5794 samples


--- 2. Setting up Model and Optimizer ---

Applying parametrization for 'ViT'...
        - WARNING: 'mf' scaling is not implemented for ViT.
        - Applying single Base LR (Î· = 1.00e-02) to all parameters.
        - All ViT parameters: LR = 1.00e-02

--- 3. Starting Training & Evaluation Loop ---
Traceback (most recent call last):
  File "/home/utsu/sp_v2/main.py", line 782, in <module>
    main(config_path='config.yaml')
  File "/home/utsu/sp_v2/main.py", line 673, in main
    train_metrics = utils.evaluate_model(model, X_train, y_train, a_train, device, loss_function_name)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/utils.py", line 93, in evaluate_model
    scores, _ = model(X_data.to(device))
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1881, in _call_impl
    return inner()
           ^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1829, in inner
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/model.py", line 329, in forward
    output_scalar = self.vit(x)
                    ^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torchvision/models/vision_transformer.py", line 298, in forward
    x = self.encoder(x)
        ^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torchvision/models/vision_transformer.py", line 157, in forward
    return self.ln(self.layers(self.dropout(input)))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torchvision/models/vision_transformer.py", line 113, in forward
    x, _ = self.self_attention(x, x, x, need_weights=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/utsu/sp_v2/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 1428, in forward
    return torch._native_multi_head_attention(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 3.84 GiB is free. Process 3882261 has 11.93 GiB memory in use. Of the allocated memory 11.47 GiB is allocated by PyTorch, and 75.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
