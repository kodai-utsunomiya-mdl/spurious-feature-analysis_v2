# # sp/config.yaml

# # ---------------------------------
# # 実験の基本設定
# # ---------------------------------
# experiment_name: "wb_dfr_layer4"
# dataset_name: "WaterBirds"  # "ColoredMNIST" or "WaterBirds"
# loss_function: "logistic"          # "logistic" or "mse"
# activation_function: "softplus"   # 'relu', 'gelu', 'tanh', 'identity', 'silu', 'softplus'
# initialization_method: "muP"  # "muP" or "NTP"
# use_skip_connections: false
# device: "cuda"                # "cuda" or "cpu"

# # ---------------------------------
# # データセット設定
# # ---------------------------------
# num_train_samples: 50000   # Waterbirdsの最大: 4795
# num_val_samples: 5000   # WaterBirdsなどで使用するValidationデータのサンプル数．# Waterbirdsの最大: 1199
# num_test_samples: 9000  # Waterbirdsの最大: 5794

# # --- 事前特徴抽出器の設定 ---
# use_feature_extractor: true

# # --- 特徴抽出器のモデル選択 ---
# # 'ResNet18', 'ResNet50', 'ViT_B_16'
# # DINOv2系: 'DINOv2_ViT_S_14' (384-dim), 'DINOv2_ViT_B_14' (768-dim),
# #            'DINOv2_ViT_L_14' (1024-dim), 'DINOv2_ViT_G_14' (1536-dim)
# feature_extractor_model_name: "DINOv2_ViT_G_14" 

# # --- ResNet系 中間層特徴マップ設定 ---
# # [ResNet系 ('ResNet18', 'ResNet50') でのみ有効]
# # 'avgpool': avgpool 後のベクトル (デフォルト)
# # 'layer3': ResNetの layer3 出力
# # 'layer4': ResNetの layer4 出力
# feature_extractor_resnet_intermediate_layer: "avgpool" 

# # 'resnet_intermediate_layer' が 'avgpool' 以外の場合の適応的空間プーリングサイズ
# # 1 -> (1x1), 2 -> (2x2), 3 -> (3x3)
# feature_extractor_resnet_pooling_output_size: 2 

# # --- ViT/DINOv2系 中間層設定 ---
# # [ViT/DINOv2系でのみ有効]
# # 抽出するブロックのインデックス (0 から N-1). 
# # -1 は最後のブロック, -2 は最後から2番目, ...
# # (ViT_B_16: 12 blocks (0-11))
# # (DINOv2_ViT_S_14, DINOv2_ViT_B_14: 12 blocks (0-11))
# # (DINOv2_ViT_L_14: 24 blocks (0-23))
# # (DINOv2_ViT_G_14: 40 blocks (0-39))
# feature_extractor_vit_target_block: -1 # デフォルトは最後のブロック

# # 'target_block' からの特徴をどう集約するか
# # 'cls_token': [CLS] トークンのみを使用 (デフォルト)
# # 'mean_pool_patch': パッチトークンのみを平均プーリング
# # 'mean_pool_all': [CLS] と パッチトークンの両方を平均プーリング
# feature_extractor_vit_aggregation_mode: "mean_pool_all" 


# # --- ColoredMNIST固有の設定 ---
# train_correlation: 0.8
# train_label_marginal: 0.0       # E[Y] (ラベル不均衡度: -1.0 ~ 1.0)
# train_attribute_marginal: 0.0   # E[A] (属性不均衡度: -1.0 ~ 1.0)
# test_correlation: 0.0
# test_label_marginal: 0.0        # E[Y] (テストセット)
# test_attribute_marginal: 0.0    # E[A] (テストセット)

# # ---------------------------------
# # モデル設定
# # ---------------------------------
# num_hidden_layers: 7
# hidden_dim: 4096

# # --------------------------------
# # 学習設定
# # ---------------------------------
# epochs: 2000
# train_batch_size: 50000   # ERMの場合の学習バッチサイズ (IW や DRO では無視する)
# eval_batch_size: 50000    # 評価時のバッチサイズ
# optimizer: "SGD"    # "SGD" or "Adam"
# learning_rate: 0.1
# momentum: 0.0
# fix_final_layer: false  # trueにすると最終層の重みを固定

# # --- バイアス除去手法の選択 ---
# debias_method: "None" # "None" (ERM), "IW_uniform", "GroupDRO" から選択

# # --- Group DRO Settings ---
# dro_eta_q: 0.01 # グループ重みqを更新するためのステップサイズ (学習率)

# # --- カーネル正則化設定 ---
# # スプリアス相関緩和のためのカーネル値 (内積) 制御
# use_kernel_regularization: false # true で有効化

# # 3項それぞれの正則化強度を個別に設定 (カーネル値)
# kernel_reg_weight_sameA_diffY: 0.5 # [最小化] 属性が同じでラベルが異なる
# kernel_reg_weight_diffA_diffY: 0.0 # [最小化] 属性が異なりラベルも異なる
# kernel_reg_weight_diffA_sameY: 0.5 # [最大化] 属性が異なりラベルが同じ

# # --- コサイン類似度正則化 (新規追加) ---
# # スプリアス相関緩和のためのコサイン類似度制御 (カーネル正則化と併用可能)
# use_cosine_regularization: false # true で有効化

# # 3項それぞれの正則化強度を個別に設定 (コサイン類似度)
# cosine_reg_weight_sameA_diffY: 1.0 # [最小化] 属性が同じでラベルが異なる
# cosine_reg_weight_diffA_diffY: 1.0 # [最小化] 属性が異なりラベルも異なる
# cosine_reg_weight_diffA_sameY: 1.0 # [最大化] 属性が異なりラベルが同じ

# # --- 正則化のスケジューリング (新規追加) ---
# # 指定したエポック以降は正則化を無効化する (null または指定なしの場合は常に有効)
# # 例: 100 と設定すると，Epoch 0～99 までは有効，Epoch 100 以降は無効になる
# regularization_end_epoch: 20000
# # regularization_decay_start_epoch: 減衰を開始するエポック (オプション)
# regularization_decay_start_epoch: 300


# # ------------------------------------------
# # 解析・可視化設定
# # ------------------------------------------
# # 各種分析の実行エポック設定 (キー自体を省略 or 値を空(None) -> 毎エポック, 空リスト[] -> 無効化)
# gap_dynamics_factors_analysis_epochs:
# jacobian_norm_analysis_epochs:
# static_dynamic_decomposition_analysis_epochs: # 静的/動的分解の分析エポック

# # 性能差ダイナミクス要因の分析設定
# gap_dynamics_factors:
#   # 分析対象とするグループペア [g1, g2] のリスト
#   group_pairs:
#     - [[-1, 1], [-1, -1]]  # 少数派・多数派
#     - [[1, -1], [-1, -1]]
#     - [[ 1,  -1], [ 1, 1]]

# # 静的・動的分解の分析設定
# static_dynamic_decomposition:
#   # 分析対象とするグループペア [g_min, g_maj] のリスト
#   # (d/dt (R_min - R_maj) の要因 (A, B, C) を計算)
#   group_pairs:
#     # y=-1 のペア (min=(-1,1), maj=(-1,-1))
#     - [[-1, 1], [-1, -1]]
#     # y=+1 のペア (min=(1,-1), maj=(1,1))
#     - [[1, -1], [1, 1]]

# # 解析対象データセット ('train', 'test', 'both')
# analysis_target: 'both'
# jacobian_num_samples: 50000    # ヤコビアンを計算するためのグループから使用するサンプル数 (カーネル正則化でも使用)
# # グループ勾配計算 (Basis/GapFactors/StaticDynamic用) のサンプル数 (null の場合は全サンプル使用)
# gradient_gram_num_samples: null 
# show_and_save_samples: false  # 実行時にデータセットのサンプル画像を表示・保存するか

# # ---------------------------------
# # 解析の有効/無効フラグ
# # ---------------------------------
# analyze_jacobian_norm: false
# analyze_gradient_basis: false
# analyze_gap_dynamics_factors: false
# analyze_static_dynamic_decomposition: false
# analyze_model_output_expectation: true

# # ---------------------------------
# # wandb設定
# # ---------------------------------
# wandb:
#   enable: true
#   project: "sp_exp_test"
#   entity: "mdl-tsukuba"

# # ---------------------------------
# # DFR (Deep Feature Reweighting) 設定
# # ---------------------------------
# use_dfr: true # True にすると学習後に DFR を実行
# dfr_reg: "l1"  # "l1" or "l2"
# dfr_c_options: [1.0, 0.7, 0.3, 0.1, 0.07, 0.03, 0.01] # チューニングする正則化強度の逆数
# dfr_num_retrains: 10 # バランスサブサンプリングを繰り返す回数 (重みを平均化)

# # --- Validationデータセットの戦略 (Validation Strategy) ---
# # 'original': データセット固有のValidationセットを使用する (存在しない場合はTrainから分割せずエラー or スキップになる場合があるため注意)
# # 'split_from_train': Trainデータの一部をValidationとして分割して使用する (Validationセットが存在する場合でも無視してTrainから作る)
# dfr_val_split_strategy: "original" 

# # 'split_from_train' の場合に使用するTrainデータの割合 (0.0 ~ 1.0)
# dfr_val_ratio: 0.2 

# # --- DFRを適用する層の指定 ---
# # "last_hidden": 最終層の直前 (MLPの最後の隠れ層の出力)．デフォルトかつ論文の設定．
# # "layer_1": 第1層の出力．"layer_2": 第2層の出力... など，MLPの中間層名を指定可能．
# dfr_target_layer: "layer_4"



















# sp/config.yaml

# ---------------------------------
# 実験の基本設定
# ---------------------------------
experiment_name: "wb_dfr_test_bias"
dataset_name: "WaterBirds"  # "ColoredMNIST" or "WaterBirds"
loss_function: "logistic"          # "logistic" or "mse"
activation_function: "softplus"   # 'relu', 'gelu', 'tanh', 'identity', 'silu', 'softplus'
initialization_method: "muP"  # "muP" or "NTP"
use_skip_connections: false
use_bias: true               # バイアス項の有無 (muPの場合はTable 9に従う)
device: "cuda"                # "cuda" or "cpu"

# ---------------------------------
# データセット設定
# ---------------------------------
num_train_samples: 50000   # Waterbirdsの最大: 4795
num_val_samples: 5000   # WaterBirdsなどで使用するValidationデータのサンプル数．# Waterbirdsの最大: 1199
num_test_samples: 9000  # Waterbirdsの最大: 5794

# --- 事前特徴抽出器の設定 ---
use_feature_extractor: true

# --- 特徴抽出器のモデル選択 ---
# 'ResNet18', 'ResNet50', 'ViT_B_16'
# DINOv2系: 'DINOv2_ViT_S_14' (384-dim), 'DINOv2_ViT_B_14' (768-dim),
#            'DINOv2_ViT_L_14' (1024-dim), 'DINOv2_ViT_G_14' (1536-dim)
feature_extractor_model_name: "DINOv2_ViT_G_14" 

# --- ResNet系 中間層特徴マップ設定 ---
# [ResNet系 ('ResNet18', 'ResNet50') でのみ有効]
# 'avgpool': avgpool 後のベクトル (デフォルト)
# 'layer3': ResNetの layer3 出力
# 'layer4': ResNetの layer4 出力
feature_extractor_resnet_intermediate_layer: "avgpool" 

# 'resnet_intermediate_layer' が 'avgpool' 以外の場合の適応的空間プーリングサイズ
# 1 -> (1x1), 2 -> (2x2), 3 -> (3x3)
feature_extractor_resnet_pooling_output_size: 2 

# --- ViT/DINOv2系 中間層設定 ---
# [ViT/DINOv2系でのみ有効]
# 抽出するブロックのインデックス (0 から N-1). 
# -1 は最後のブロック, -2 は最後から2番目, ...
# (ViT_B_16: 12 blocks (0-11))
# (DINOv2_ViT_S_14, DINOv2_ViT_B_14: 12 blocks (0-11))
# (DINOv2_ViT_L_14: 24 blocks (0-23))
# (DINOv2_ViT_G_14: 40 blocks (0-39))
feature_extractor_vit_target_block: -1 # デフォルトは最後のブロック

# 'target_block' からの特徴をどう集約するか
# 'cls_token': [CLS] トークンのみを使用 (デフォルト)
# 'mean_pool_patch': パッチトークンのみを平均プーリング
# 'mean_pool_all': [CLS] と パッチトークンの両方を平均プーリング
feature_extractor_vit_aggregation_mode: "mean_pool_all" 


# --- ColoredMNIST固有の設定 ---
train_correlation: 0.8
train_label_marginal: 0.0       # E[Y] (ラベル不均衡度: -1.0 ~ 1.0)
train_attribute_marginal: 0.0   # E[A] (属性不均衡度: -1.0 ~ 1.0)
test_correlation: 0.0
test_label_marginal: 0.0        # E[Y] (テストセット)
test_attribute_marginal: 0.0    # E[A] (テストセット)

# ---------------------------------
# モデル設定
# ---------------------------------
num_hidden_layers: 7
hidden_dim: 4096

# --------------------------------
# 学習設定
# ---------------------------------
epochs: 2000
train_batch_size: 50000   # ERMの場合の学習バッチサイズ (IW や DRO では無視する)
eval_batch_size: 50000    # 評価時のバッチサイズ
optimizer: "SGD"    # "SGD" or "Adam"
learning_rate: 0.1
momentum: 0.0
fix_final_layer: false  # trueにすると最終層の重みを固定

# --- バイアス除去手法の選択 ---
debias_method: "None" # "None" (ERM), "IW_uniform", "GroupDRO" から選択

# --- Group DRO Settings ---
dro_eta_q: 0.01 # グループ重みqを更新するためのステップサイズ (学習率)

# --- カーネル正則化設定 ---
# スプリアス相関緩和のためのカーネル値 (内積) 制御
use_kernel_regularization: false # true で有効化

# 3項それぞれの正則化強度を個別に設定 (カーネル値)
kernel_reg_weight_sameA_diffY: 0.5 # [最小化] 属性が同じでラベルが異なる
kernel_reg_weight_diffA_diffY: 0.0 # [最小化] 属性が異なりラベルも異なる
kernel_reg_weight_diffA_sameY: 0.5 # [最大化] 属性が異なりラベルが同じ

# --- コサイン類似度正則化 (新規追加) ---
# スプリアス相関緩和のためのコサイン類似度制御 (カーネル正則化と併用可能)
use_cosine_regularization: false # true で有効化

# 3項それぞれの正則化強度を個別に設定 (コサイン類似度)
cosine_reg_weight_sameA_diffY: 1.0 # [最小化] 属性が同じでラベルが異なる
cosine_reg_weight_diffA_diffY: 1.0 # [最小化] 属性が異なりラベルも異なる
cosine_reg_weight_diffA_sameY: 1.0 # [最大化] 属性が異なりラベルが同じ

# --- 正則化のスケジューリング (新規追加) ---
# 指定したエポック以降は正則化を無効化する (null または指定なしの場合は常に有効)
# 例: 100 と設定すると，Epoch 0～99 までは有効，Epoch 100 以降は無効になる
regularization_end_epoch: 20000
# regularization_decay_start_epoch: 減衰を開始するエポック (オプション)
regularization_decay_start_epoch: 300


# ------------------------------------------
# 解析・可視化設定
# ------------------------------------------
# 各種分析の実行エポック設定 (キー自体を省略 or 値を空(None) -> 毎エポック, 空リスト[] -> 無効化)
gap_dynamics_factors_analysis_epochs:
jacobian_norm_analysis_epochs:
static_dynamic_decomposition_analysis_epochs: # 静的/動的分解の分析エポック

# 性能差ダイナミクス要因の分析設定
gap_dynamics_factors:
  # 分析対象とするグループペア [g1, g2] のリスト
  group_pairs:
    - [[-1, 1], [-1, -1]]  # 少数派・多数派
    - [[1, -1], [-1, -1]]
    - [[ 1,  -1], [ 1, 1]]

# 静的・動的分解の分析設定
static_dynamic_decomposition:
  # 分析対象とするグループペア [g_min, g_maj] のリスト
  # (d/dt (R_min - R_maj) の要因 (A, B, C) を計算)
  group_pairs:
    # y=-1 のペア (min=(-1,1), maj=(-1,-1))
    - [[-1, 1], [-1, -1]]
    # y=+1 のペア (min=(1,-1), maj=(1,1))
    - [[1, -1], [1, 1]]

# 解析対象データセット ('train', 'test', 'both')
analysis_target: 'both'
jacobian_num_samples: 50000    # ヤコビアンを計算するためのグループから使用するサンプル数 (カーネル正則化でも使用)
# グループ勾配計算 (Basis/GapFactors/StaticDynamic用) のサンプル数 (null の場合は全サンプル使用)
gradient_gram_num_samples: null 
show_and_save_samples: false  # 実行時にデータセットのサンプル画像を表示・保存するか

# ---------------------------------
# 解析の有効/無効フラグ
# ---------------------------------
analyze_jacobian_norm: false
analyze_gradient_basis: false
analyze_gap_dynamics_factors: false
analyze_static_dynamic_decomposition: false
analyze_model_output_expectation: true

# ---------------------------------
# wandb設定
# ---------------------------------
wandb:
  enable: true
  project: "sp_exp_test"
  entity: "mdl-tsukuba"

# ---------------------------------
# DFR (Deep Feature Reweighting) 設定
# ---------------------------------
use_dfr: true # True にすると学習後に DFR を実行
dfr_reg: "l1"  # "l1" or "l2"
dfr_c_options: [1.0, 0.7, 0.3, 0.1, 0.07, 0.03, 0.01] # チューニングする正則化強度の逆数
dfr_num_retrains: 10 # バランスサブサンプリングを繰り返す回数 (重みを平均化)

# --- Validationデータセットの戦略 (Validation Strategy) ---
# 'original': データセット固有のValidationセットを使用する (存在しない場合はTrainから分割せずエラー or スキップになる場合があるため注意)
# 'split_from_train': Trainデータの一部をValidationとして分割して使用する (Validationセットが存在する場合でも無視してTrainから作る)
dfr_val_split_strategy: "original" 

# 'split_from_train' の場合に使用するTrainデータの割合 (0.0 ~ 1.0)
dfr_val_ratio: 0.2 

# --- DFRを適用する層の指定 ---
# "last_hidden": 最終層の直前 (MLPの最後の隠れ層の出力)．デフォルトかつ論文の設定．
# "layer_1": 第1層の出力．"layer_2": 第2層の出力... など，MLPの中間層名を指定可能．
dfr_target_layer: "layer_4"
